{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "This notebook will answer all the questions in part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\qkm20\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\qkm20\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\qkm20\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from utils.rnn_model import *\n",
    "from utils.rnn_utils import *\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation \n",
    "\n",
    "First, we define all relevant hyperparameters, then we load the dataset.\n",
    "\n",
    "After which, we will load the word embeddings and process the data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "trn_dataset = dataset[\"train\"]\n",
    "val_dataset = dataset[\"validation\"]\n",
    "tst_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding\n",
    "\n",
    "We load the pre-trained Google News 300 dimension Word2Vec model and obtain a word index to be used later in data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = load_word2vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {\n",
    "    word: i for i, word in enumerate(\n",
    "        word2vec_model.index_to_key\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders\n",
    "\n",
    "Once we have the dataset and the word index both loaded, we can proceed with building the dataloaders for batch training. We first prepare the data by tokenizing and padding the data so that they are all of the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_sentences, trn_labels = prepare_data(\n",
    "    trn_dataset[\"text\"],\n",
    "    trn_dataset[\"label\"],\n",
    "    word_index=word_index\n",
    ")\n",
    "val_sentences, val_labels = prepare_data(\n",
    "    val_dataset[\"text\"],\n",
    "    val_dataset[\"label\"],\n",
    "    word_index=word_index\n",
    ")\n",
    "tst_sentences, tst_labels = prepare_data(\n",
    "    tst_dataset[\"text\"],\n",
    "    tst_dataset[\"label\"],\n",
    "    word_index=word_index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is processed, we create dataloaders for the data for batch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataloader = create_dataloader(\n",
    "    trn_sentences,\n",
    "    trn_labels,\n",
    "    BATCH_SIZE,\n",
    "    shuffle=True)\n",
    "val_dataloader = create_dataloader(\n",
    "    val_sentences,\n",
    "    val_labels,\n",
    "    BATCH_SIZE,\n",
    "    shuffle=False)\n",
    "tst_dataloader = create_dataloader(\n",
    "    tst_sentences,\n",
    "    tst_labels,\n",
    "    BATCH_SIZE,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we define all relevant hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "MODEL_TYPE = \"rnn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default RNN\n",
    "\n",
    "We initialise the model for the default RNN without any extra processing to derive the final sentence representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(\n",
    "    embedding_dim=300,\n",
    "    hidden_size=256,\n",
    "    embedding_matrix=word2vec_model.vectors,\n",
    "    rnn_type=MODEL_TYPE,\n",
    "    bidirectional=False,\n",
    "    num_layers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the data is loaded and processed into Dataloaders, we can start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100, Loss: 0.6527, Accuracy: 0.7214\n",
      "Model saved.\n",
      "Epoch   2/100, Loss: 0.5389, Accuracy: 0.7608\n",
      "Model saved.\n",
      "Epoch   3/100, Loss: 0.5156, Accuracy: 0.7486\n",
      "Epoch   4/100, Loss: 0.5026, Accuracy: 0.7561\n",
      "Epoch   5/100, Loss: 0.4955, Accuracy: 0.7477\n",
      "Epoch   6/100, Loss: 0.4916, Accuracy: 0.7467\n",
      "Epoch   7/100, Loss: 0.4894, Accuracy: 0.7439\n",
      "Epoch   8/100, Loss: 0.4778, Accuracy: 0.7636\n",
      "Model saved.\n",
      "Epoch   9/100, Loss: 0.4680, Accuracy: 0.7486\n",
      "Epoch  10/100, Loss: 0.4575, Accuracy: 0.7552\n",
      "Epoch  11/100, Loss: 0.4453, Accuracy: 0.7477\n",
      "Epoch  12/100, Loss: 0.4325, Accuracy: 0.7364\n",
      "Epoch  13/100, Loss: 0.4207, Accuracy: 0.7280\n",
      "Epoch  14/100, Loss: 0.4049, Accuracy: 0.7205\n",
      "Epoch  15/100, Loss: 0.3997, Accuracy: 0.7129\n",
      "Epoch  16/100, Loss: 0.3844, Accuracy: 0.7261\n",
      "Epoch  17/100, Loss: 0.3727, Accuracy: 0.7186\n",
      "Epoch  18/100, Loss: 0.3666, Accuracy: 0.7054\n",
      "Early stopping triggered after 18 epochs.\n",
      "Training ended, loading best model...\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    trn_dataloader=trn_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    version=\"1\",\n",
    "    model_type=MODEL_TYPE,\n",
    "    model_save_path=os.getenv(\"MODEL_SAVE_PATH\", \"modelfiles/\"),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=LR),\n",
    "    epochs=100,\n",
    "    early_stopping_patience=10,\n",
    "    train_mode=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the validation check again to make sure we've loaded the right model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7636\n"
     ]
    }
   ],
   "source": [
    "val_accuracy = validate(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on the test set to obtain the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7364\n"
     ]
    }
   ],
   "source": [
    "tst_accuracy = validate(model, tst_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last State RNN\n",
    "\n",
    "This RNN will pick the hidden vector from the last time step as the sentence representation. This approach assumes that the last hidden state will capture the overall meaning of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(\n",
    "    embedding_dim=300,\n",
    "    hidden_size=256,\n",
    "    embedding_matrix=word2vec_model.vectors,\n",
    "    rnn_type=MODEL_TYPE,\n",
    "    bidirectional=False,\n",
    "    num_layers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the data is loaded and processed into Dataloaders, we can start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100, Loss: 0.6648, Accuracy: 0.7392\n",
      "Model saved.\n",
      "Epoch   2/100, Loss: 0.5354, Accuracy: 0.7486\n",
      "Model saved.\n",
      "Epoch   3/100, Loss: 0.5125, Accuracy: 0.7533\n",
      "Model saved.\n",
      "Epoch   4/100, Loss: 0.5042, Accuracy: 0.7495\n",
      "Epoch   5/100, Loss: 0.4986, Accuracy: 0.7552\n",
      "Model saved.\n",
      "Epoch   6/100, Loss: 0.4895, Accuracy: 0.7514\n",
      "Epoch   7/100, Loss: 0.4850, Accuracy: 0.7505\n",
      "Epoch   8/100, Loss: 0.4801, Accuracy: 0.7542\n",
      "Epoch   9/100, Loss: 0.4712, Accuracy: 0.7505\n",
      "Epoch  10/100, Loss: 0.4624, Accuracy: 0.7439\n",
      "Epoch  11/100, Loss: 0.4498, Accuracy: 0.7439\n",
      "Epoch  12/100, Loss: 0.4383, Accuracy: 0.7383\n",
      "Epoch  13/100, Loss: 0.4258, Accuracy: 0.7317\n",
      "Epoch  14/100, Loss: 0.4160, Accuracy: 0.7270\n",
      "Epoch  15/100, Loss: 0.4035, Accuracy: 0.7336\n",
      "Early stopping triggered after 15 epochs.\n",
      "Training ended, loading best model...\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    trn_dataloader=trn_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    version=\"1\",\n",
    "    model_type=MODEL_TYPE,\n",
    "    model_save_path=os.getenv(\"MODEL_SAVE_PATH\", \"modelfiles/\"),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=LR),\n",
    "    epochs=100,\n",
    "    early_stopping_patience=10,\n",
    "    train_mode=\"last_state\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the validation check again to make sure we've loaded the right model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "val_accuracy = validate(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on the test set to obtain the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7373\n"
     ]
    }
   ],
   "source": [
    "tst_accuracy = validate(model, tst_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Pooling RNN\n",
    "\n",
    "This RNN will use the average of all hidden vectors as the sentence representation. This captures information across the whole sentence by averaging the all the words' contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(\n",
    "    embedding_dim=300,\n",
    "    hidden_size=256,\n",
    "    embedding_matrix=word2vec_model.vectors,\n",
    "    rnn_type=MODEL_TYPE,\n",
    "    bidirectional=False,\n",
    "    num_layers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the data is loaded and processed into Dataloaders, we can start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100, Loss: 0.6644, Accuracy: 0.7064\n",
      "Model saved.\n",
      "Epoch   2/100, Loss: 0.5367, Accuracy: 0.7111\n",
      "Model saved.\n",
      "Epoch   3/100, Loss: 0.5131, Accuracy: 0.7505\n",
      "Model saved.\n",
      "Epoch   4/100, Loss: 0.5049, Accuracy: 0.7542\n",
      "Model saved.\n",
      "Epoch   5/100, Loss: 0.4977, Accuracy: 0.7411\n",
      "Epoch   6/100, Loss: 0.4920, Accuracy: 0.7533\n",
      "Epoch   7/100, Loss: 0.4860, Accuracy: 0.7533\n",
      "Epoch   8/100, Loss: 0.4812, Accuracy: 0.7552\n",
      "Model saved.\n",
      "Epoch   9/100, Loss: 0.4692, Accuracy: 0.7533\n",
      "Epoch  10/100, Loss: 0.4637, Accuracy: 0.7261\n",
      "Epoch  11/100, Loss: 0.4526, Accuracy: 0.7477\n",
      "Epoch  12/100, Loss: 0.4387, Accuracy: 0.7411\n",
      "Epoch  13/100, Loss: 0.4278, Accuracy: 0.7364\n",
      "Epoch  14/100, Loss: 0.4188, Accuracy: 0.7326\n",
      "Epoch  15/100, Loss: 0.4084, Accuracy: 0.7345\n",
      "Epoch  16/100, Loss: 0.3991, Accuracy: 0.7139\n",
      "Epoch  17/100, Loss: 0.3915, Accuracy: 0.7289\n",
      "Epoch  18/100, Loss: 0.3753, Accuracy: 0.7073\n",
      "Early stopping triggered after 18 epochs.\n",
      "Training ended, loading best model...\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    trn_dataloader=trn_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    version=\"1\",\n",
    "    model_type=MODEL_TYPE,\n",
    "    model_save_path=os.getenv(\"MODEL_SAVE_PATH\", \"modelfiles/\"),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=LR),\n",
    "    epochs=100,\n",
    "    early_stopping_patience=10,\n",
    "    train_mode=\"mean_pool\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the validation check again to make sure we've loaded the right model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "val_accuracy = validate(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on the test set to obtain the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7402\n"
     ]
    }
   ],
   "source": [
    "tst_accuracy = validate(model, tst_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pool RNN\n",
    "\n",
    "This RNN will compute the max of all hidden vectors along each dimension. This will effectively use the most significant word as the representation of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(\n",
    "    embedding_dim=300,\n",
    "    hidden_size=256,\n",
    "    embedding_matrix=word2vec_model.vectors,\n",
    "    rnn_type=MODEL_TYPE,\n",
    "    bidirectional=False,\n",
    "    num_layers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the data is loaded and processed into Dataloaders, we can start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100, Loss: 0.6549, Accuracy: 0.7402\n",
      "Model saved.\n",
      "Epoch   2/100, Loss: 0.5338, Accuracy: 0.7477\n",
      "Model saved.\n",
      "Epoch   3/100, Loss: 0.5127, Accuracy: 0.7561\n",
      "Model saved.\n",
      "Epoch   4/100, Loss: 0.5037, Accuracy: 0.7439\n",
      "Epoch   5/100, Loss: 0.4981, Accuracy: 0.7561\n",
      "Epoch   6/100, Loss: 0.4927, Accuracy: 0.7505\n",
      "Epoch   7/100, Loss: 0.4880, Accuracy: 0.7523\n",
      "Epoch   8/100, Loss: 0.4827, Accuracy: 0.7636\n",
      "Model saved.\n",
      "Epoch   9/100, Loss: 0.4767, Accuracy: 0.7664\n",
      "Model saved.\n",
      "Epoch  10/100, Loss: 0.4693, Accuracy: 0.7439\n",
      "Epoch  11/100, Loss: 0.4608, Accuracy: 0.7495\n",
      "Epoch  12/100, Loss: 0.4546, Accuracy: 0.7495\n",
      "Epoch  13/100, Loss: 0.4397, Accuracy: 0.7308\n",
      "Epoch  14/100, Loss: 0.4280, Accuracy: 0.7345\n",
      "Epoch  15/100, Loss: 0.4196, Accuracy: 0.7326\n",
      "Epoch  16/100, Loss: 0.4094, Accuracy: 0.7036\n",
      "Epoch  17/100, Loss: 0.3970, Accuracy: 0.7345\n",
      "Epoch  18/100, Loss: 0.3856, Accuracy: 0.7289\n",
      "Epoch  19/100, Loss: 0.3728, Accuracy: 0.7120\n",
      "Early stopping triggered after 19 epochs.\n",
      "Training ended, loading best model...\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    trn_dataloader=trn_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    version=\"1\",\n",
    "    model_type=MODEL_TYPE,\n",
    "    model_save_path=os.getenv(\"MODEL_SAVE_PATH\", \"modelfiles/\"),\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=LR),\n",
    "    epochs=100,\n",
    "    early_stopping_patience=10,\n",
    "    train_mode=\"max_pool\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the validation check again to make sure we've loaded the right model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7664\n"
     ]
    }
   ],
   "source": [
    "val_accuracy = validate(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on the test set to obtain the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7430\n"
     ]
    }
   ],
   "source": [
    "tst_accuracy = validate(model, tst_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc4002",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
